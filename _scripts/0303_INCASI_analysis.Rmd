---
title: "0303_INCASI_analysis"
author: "Stella Kunzendorf"
date: "18. October 2018"
output: html_document
---

**MAIN ANALYSIS**:

**1. ENCODING**

1a. Circular analysis (Fig. 1b, Fig. 2a)

1b. Binary analysis (Fig. 2b)


**2. RECOGNITION**

2a. Circular analysis 

2b. Binary analysis (Table 1)


**SUPPLEMENTARY ANALYSIS**

1. Correlation of self-paced sampling with inter-individual differences (Fig. 3)

2. Correlation of recognition memory with inter-individual differences (Fig. 4)

3. Analyse ratings: Subjective perception of picture emotionality (Fig. 5)

4. Test match of picture features (physical, social)


**SUPPLEMENTARY METHODS**

1. Correlation of systole and HR (Fig. S1)

2. Ranges and lengths of cardiac phases (Fig. S2)


### INCASI SETUP

- If you have done your own preprocessing (and you have the folder **0303_INCASI_data**), please change the parameter `use_own_preproc_data` in the setup chunk of `0303_INCASI_analysis.Rmd` to `TRUE`

#### 1. General setup
```{r INCASI setup, message = FALSE}
#--------------------------------------------------------------------------
# Clear workspace
# rm(list=ls())

#--------------------------------------------------------------------------
# Have you done your own preprocessing? 
# If so, change this parameter:
use_own_preproc_data <- F

#--------------------------------------------------------------------------
# Set working directory to containing folder ('0303_INCASI'):

# knitr automatically sets this to the folder that contains the script 
# (here 0303_INCASI/_scripts)

#--------------------------------------------------------------------------
# Define paths:
path_wd 	 <- getwd()
path_data <- paste("../../0303_INCASI_data/",sep="") # path to folder: 0303_INCASI_data
path_scripts  <- paste("../_scripts/",sep="") # path to folder: _scripts
path_functions  <- paste("../_functions/",sep="") # path to folder: _functions
path_dataframes <- paste("../_dataframes/",sep="") # path to folder: _dataframes
path_variables <- paste("../_variables/",sep="") # path to folder: _variables
path_figures <- paste("../_figures/",sep="") # path to folder: _figures

#--------------------------------------------------------------------------
# load packages
source(paste(path_scripts,"loadPackages.R",sep="")) # installed Rpackages

#--------------------------------------------------------------------------
# load settings for ggplot
source(paste(path_scripts,"loadTheme.R",sep="")) # ggplot theme
source(paste(path_scripts,"loadColors.R",sep="")) # ggplot colours

#--------------------------------------------------------------------------
```


####  2. Load dataframes for analysis: 

Coding of cardiac phases:

* **Systole** (syspat = lvet, i.e. left ventricular ejection period): sys1 + sys2
* **Diastole** (alldias): dias1-dias4 (4 diastolic intervals of same length)
* Non-defined: pep (pre-ejection phase), security window (50ms between end of systole and start diastole)

* Load dataframes created in preprocessing scripts
```{r scripts analysis, message = FALSE}
#----------------------------------------------------------------------------
# dataframes for analysis behaviour relative to cardiac cycle
load(paste(path_dataframes,"log_encode.RData", sep="")) # long dataframe encoding (all datapoints from encoding)
load(paste(path_dataframes,"data_bins.RData", sep="")) # short dataframe encoding (1 subject each row)

# dataframes for exploratory analysis rating
load(paste(path_dataframes, "log_rate.RData", sep="")) # long dataframe rating (all datapoints from rating period)

load(paste(path_dataframes, "rate_va.RData", sep="")) # df with normative and individual ratings for each picture (180 pictures)

#--------------------------------------------------------------------------
# define list of participants that survived preprocessing
if (use_own_preproc_data) {
  #create list with participants 
  inc_list <- as.factor(dir(path_data)) 
} else {
  # with our preprocessing, 46(/47) participants go into the analysis (exluding 48).
  # Grabbing their IDs from one of the preprocessed DFs:
  inc_list <- as.factor(unique(log_encode$vp))
}

#----------------------------------------------------------------------------
```


####  3. Load dataframes of additional variables
```{r load covariate scripts, results='hide'}
#--------------------------------------------------------------------------
# Age
load(paste(path_dataframes, "data_age.RData", sep="")) # heart beat perception score df

# Blood pressure
load(paste(path_dataframes, "data_bp.RData", sep="")) # heart beat perception score df

# Interoceptive accuracy (IA)
load(paste(path_dataframes, "score.RData", sep="")) # heart beat perception score df

# Heart rate variability (HRV)
load(paste(path_dataframes, "kubios.RData", sep="")) # kubios (mean HR, rmssd) df from resting phase

# State Trait Anxiety (STAI)
load(paste(path_dataframes, "stai.RData", sep="")) # STAI-T (trait anxiety) df
#--------------------------------------------------------------------------
```


####  4. Load functions
```{r circular functions}
#----------------------------------------------------------------------------
# load functions for circular analysis
source(paste(path_functions, "fx_circ_encoding.R", sep="")) # circular function for picture onsets relative to cardiac cycle (encoding period)
source(paste(path_functions, "fx_circ_recognition.R", sep="")) # circular function for memory relative to picture onset in encoding (recognition period)

# load helper functions
source(paste(path_functions, "fx_standard_error.R", sep="")) # function to calculate standard error
#----------------------------------------------------------------------------
```


####  5. Clean participant list 

* load clean participant list (n=43)
* adapt to preregistered size (n=40)
```{r inc_clean, results='hide'}
#--------------------------------------------------------------------------
# load clean inc_lists
source(paste(path_scripts, "0303_Clean_inc_list.R", sep ="")) # load clean participant list

# inc_clean <- inc_clean[c(1:40)] # take only fist 40 participants out of clean inc list (to test with dataset of preregistration size)
#--------------------------------------------------------------------------
```



# MAIN ANALYSIS

## 1. ENCODING - Cardiac influence on visual sampling

* Adapt dataframe to clean participant list
```{r enc adapt dataframe}
#--------------------------------------------------------------------------
# data_bins_enc: Create subset data_bins for encoding
log_encode <- log_encode[log_encode$vp %in% inc_clean,]
data_bins_enc <- data_bins[data_bins$vp %in% inc_clean,] #--------------------------------------------------------------------------
```


### 1.A. CIRCULAR ANALYSIS

* Relative onset of each self-chosen key press (i.e. stimulus onset) was computed across the cardiac cycle (from Rpeak to Rpeak), with radian measures (between 0 and 2Ï€) assigned to each stimulus onset (c.f. `0303_INCASI_preprocess_b`)
* Distribution of stimulus onsets is tested against the circular unifrom distribution with Rayleigh tests
* Apply function circ_click (loaded under script `fx_circ_encoding.R`)

#### 1.A.1. Exemplary participant-level analysis (Fig. 1b)

* Exemplary stimulus distribution (120 black dots) across the cardiac cycle (Rpeak = 0) of one participant

**Figure 1.b.**

* Orange segment: individual systole (start: solid, end: dashed)
* Blue segment: individual diastole (start: solid, end: dashed)
* Grey arrow: overall picture onset mean
* Grey line: circular density of picture onsets
```{r test participant-level against uniform}
#--------------------------------------------------------------------------
# plot exemplary individual plot  
# pdf(file = paste(path_figures, "circ_click_sub25.pdf", sep=""), width=5, height=5)
circ_click("inc25", plot1 = T, ray1 = T) # distribution of key-presses (picture onsets)
# dev.off()
#--------------------------------------------------------------------------
```


#### 1.A.2. Group-level analysis 

* Distribution of participants' stimulus onset means (43 black dots) across the cardiac cycle
* Hypothesis: significant deviation of means from circular uniform distribution in early cardiac phase

Figure (for visualization purposes, not included in manuscript):

* Orange lines: individual means that fall into individual systole
* Blue lines: individual diastolic means
* Grey lines: individual means in non-defined cardiac intervals
* Black arrow: overall picture onset mean across participants
```{r test group-level against uniform}
#--------------------------------------------------------------------------
# 1. distribution of clicks in encoding
# pdf(file = paste(path_figures, "circ_click_big.pdf", sep=""),width=5,height=5)
circ_click(inc_clean, plot2 = T, ray2 = T) # distribution of clicks without inc_HyperHR, inc_Err
# dev.off()

# print overall circular mean and sd (in radian)
mean2 <- circ_click(inc_clean, mean2 = T)

# calculate circular mean in pi: mean2 = mean2pi *pi
mean2pi <- mean2[1] / pi
sd2pi <- mean2[4] / pi
#--------------------------------------------------------------------------
```


#### 1.A.3. Bootstrapping analysis (Fig. 2a)
* Non-parametical computation of confidence intervals and significance (based on Ohl et al., 2016)

Bootstrap procedure:

* From the original pool (N=43), a bootstrap sample (N=43) is drawn (with replacement)
* For each participant in the bootstrap sample, a circular density (bw = 20) of picture onsets is computed
* In the next step, the mean circular density across all participants in the bootstrap sample is computed

* This bootstrap procedure is repeated 10000 times
* 95% confidence intervals are determined as 2.5% and 97.5% percentiles from the distribution of mean circular densities

Please be aware that this might result in quite extensive run-time, depending on the system and machine that you are using. Will be particularly slow for Windows as the currently implemented parallelization does not work on Windows (script won't be aborted but run sequentially >> slow).
You can consider to decrease the number of bootstrap repetitions to for example 100 (default is 10000).
```{r boostrap}
#--------------------------------------------------------------------------
# bootstrap main analysis


nBoot  <- 10000 # number of bootstrap procedures: default = 10000, switch to 100 if necessary
vplist <- inc_clean #unique(log_encode$vp) # list of participants

# set up output variables
out    <- c()
buffer <- c()
bwparam <- 20 # bandwith parameter

# a) run whole bootstrap procedure
# start loop
tot_tme <- system.time({
  for(i in 1:nBoot){ # repeat bootstrap procedure nBoot times
    tme <- system.time({
    vplist_boot <- sample(vplist,replace=TRUE) # draw bootstrap sample
    buffer <- c()
    for(j in 1:length(vplist_boot)){ # compute circular density for each participant in sample
      x=circular(log_encode$radclick[which(log_encode$vp==vplist_boot[j])],type="angles",units="radians",modulo="2pi",zero=pi/2,rotation="clock")
      res50x  <- density(x, bw=bwparam) #Play around with bw. Make chi-square tests and check whether observed coupling is observed for all kinds of bw parameters
      readout <- as.vector(res50x$y)
      buffer  <- rbind(buffer,readout,deparse.level=0)
    }
    buffer  <- colMeans(buffer)
    out <- rbind(out,buffer)})
    
    if (i%%round(nBoot/10) == 0) {
      cat("\014")  
      print(paste('Iteration ', num2str(i, fmt=0), ' of ', num2str(nBoot, fmt=0)))
      print(paste('Time until end: ', num2str(tme[3]*(nBoot-i)/60), 'minutes'))
    }
  }
})

cat("\014")
print(paste('Total runtime: ', num2str(tot_tme[3]/60), 'minutes for ',  
             num2str(nBoot, fmt=0), ' repetitions'))


# save(res50x, file = paste(path_dataframes,"res50x.RData", sep="")) # save density
# save(out, file = paste(path_dataframes,"out.RData", sep="")) # save bootstrap output

#--------------------------------------------------------------------------
# b) if boostrap procedure is already run, load bootstrap dataframes
# load bootstrap dataframes
# load(paste(path_dataframes,"res50x.RData", sep="")) 
# load(paste(path_dataframes,"out.RData", sep="")) 

# get 95% confidence intervals and median from bootstraps (quantiles: 0.025, 0.5, 0.975)
ci_upper  <- c()
ci_lower  <- c()
ci_median <- c() 
for(i in 1:ncol(out)){
  ci_lower  <- c(ci_lower, as.numeric(quantile(out[,i],0.025))) # 2.5% percentile 
  ci_upper  <- c(ci_upper, as.numeric(quantile(out[,i],0.975))) # 97.5% percentile
  ci_median <- c(ci_median, as.numeric(quantile(out[,i],0.5))) # median
}
markup_upper <- which(ci_lower>dcircularuniform(1)) # where ci_lower (2.5%) outside uniform -> significantly more picture onsets
markup_lower <- which(ci_upper<dcircularuniform(1)) # where ci_upper (97.5%) inside uniform -> significantly less picture onsets
#--------------------------------------------------------------------------
```


Plot bootstrap density on circular plot with individual picture onset means:

**Figure 2.a**:

* Circular distribution of individual mean picture onsets (black dots, N = 43)
* Black arrow: weighted overall mean of picture onsets as black arrow
* Middle thicker line: mean circular density of picture onsets (based on bootstrap procedure)
* Orange segment: mean systole
* Blue segment: mean diastole
* Grey: non-defined phases
* Inner and outer thin grey lines: inner and out bound of 95% CI

```{r boostrap plot}
#--------------------------------------------------------------------------
# plot bootstrap results

# 1. load circular data of 2nd level analysis (circular mean picture onsets for each participant)
load(paste(path_dataframes,"H_rad_secondlevel.RData", sep="")) 

par(mar=c(0,0,0,0))
# pdf(file = paste(path_figures, "bootstrap_bw",bwparam,".pdf",sep=""),width=6.5,height=6.5)

# 2. plot circular plot with mean picture onsets (43 black dots)
plot(H_rad_secondlevel, stack=TRUE, bins = 720, shrink = 1.0, axes = T, col= "black",cex = 1.0, lwd = 3, 
     xlim=c(-1.22,1.22),ylim=c(-1.22,1.221)) # circular plot of 2nd level means

# 3. add bootstrap density to plot
res50x$y <- ci_median/dcircularuniform(1) 
lines.circular(res50x$x,res50x$y,join=TRUE,col=defgrey,offset=0,rotation="clock",lwd=4)

# 4. compute mean length of cardiac phases (systole, diastole) over all participants
# transform mean lengths of cardiac phases into radian
dat <- data_bins_enc
mcirctrans <- mean(2 * pi * 1/(dat$R_R_s)) # circular transformation
msysstart <- mean(mcirctrans * (dat$crop)) # mean systole start
msysend <- mean(mcirctrans * (dat$Rtend_s)) # mean systole end
mdiasstart <- mean(mcirctrans * (dat$Rtend_s + 0.05)) # mean diastole start
mdiasend <- mean(mcirctrans * (dat$Rtend_s + 0.05 + dat$diaspat)) # mean diastole end

# 5. colour the systolic and diastolic segments of the circular density
x <- res50x$x # x coordinates of points on density
msyspos <- which(x >= msysstart & x <= msysend) # position of points for systole
mdiaspos <- which(x >= mdiasstart & x <= mdiasend) # position of points for diastole

lines.circular(res50x$x[msyspos],res50x$y[msyspos],join=F,col=deforange,offset=0,rotation="clock",lwd=3) # draw systolic density segment (orange)
lines.circular(res50x$x[mdiaspos],res50x$y[mdiaspos],join=F,col=defmedblue,offset=0,rotation="clock",lwd=3) # draw diastolic density segment (blue)

# #check fit of segments (compute beginning and end of systolic, diastolic segment)
# # function to draw line segments onto circular plot
# circseg <- function (a, lty, col) { # define a= radians value to draw segment at, lty = linetype (1 = normal, 2 = dashed)
#   xcoord <- sin(a)
#   ycoord <- cos(a)
#   segments(0,0,xcoord, ycoord, col = col, lty= lty, lwd = 2)
# }
# 
# # check fit of density segments
# circseg(msysstart, 1, deforange) # sys start
# circseg(msysend, 2, deforange) # sys end
# circseg(mdiasstart, 1, defmedblue) # dias start
# circseg(mdiasend, 2, defmedblue) # dias stop

# 6. plot significant density segment (part where significantly more picture onsets)
lines.circular(res50x$x[markup_upper],res50x$y[markup_upper],col=deforange,lwd=8,offset=0,rotation="clock")

# 7. plot lower and upper bound of confidence interval
res50x$y <- ci_lower/dcircularuniform(1) # lower bound
lines.circular(res50x$x,res50x$y,join=TRUE,col="light grey",offset=0,rotation="clock",lwd=2)
res50x$y <- ci_upper/dcircularuniform(1) # upper bound
lines.circular(res50x$x,res50x$y,join=TRUE,col="light grey",offset=0,rotation="clock",lwd=2)

# 8. plot central cross to mark center of circle
segments(0,0,0.05,0, lwd = 2)
segments(0,0,-0.05,0, lwd = 2)
segments(0,0.05,0,0, lwd = 2)
segments(0,-0.05,0,0, lwd = 2)

# 9. plot overall circular mean of picture onsets
arrows.circular(mean(H_rad_secondlevel), y=rho.circular(H_rad_secondlevel), lwd = 5, col = "black") # overall mean

# dev.off()
#--------------------------------------------------------------------------
```


### 1.B. BINARY ANALYSIS

Analysis of individual cardiac phases: compare phases, i.e. individual systole (lvet = left ventricular ejection period) and diastole against each other 

Analyse ratios between both phases (systole, diastole) to take into account inter-individual differences in phase lengths:

* Sum of clicks (picture onsets) per phase (as ratio of all 120 trials) is normalized to the proportion of the subject-specific phase length in the total cardiac cycle
* Define ratios: (clicks per phase / 120) / (individual phase length/ individual mean R-R length)

* With no cardiac effect: clicks (triggering picture onsets) would be randomly distributed across both cardiac phases -> click ratio (clicks/120) should correspond to cardiac phase ratio (phase length/whole cycle) -> ratio value = 1
* With cardiac effect: over-proportional accumulation of key presses in systole -> systolic ratio value > 1

* Hypothesis: significant accumulation of clicks in individual systole: ratio value for systole > diastolic ratio


#### 1.B.1 Define ratios for both phases (systole, diastole):
```{r enc define ratios}
#--------------------------------------------------------------------------
# compute ratios for each phase

## SYSTOLE
# single systolic phases
data_bins_enc$click_pep_rel <- (data_bins_enc$click_pep/120) /  (data_bins_enc$pep/data_bins_enc$R_R_s) # pre-ejection period
data_bins_enc$click_sys1_rel <- (data_bins_enc$click_sys1/120) /  ((0.5 * data_bins_enc$syspat)/data_bins_enc$R_R_s) # first 1/2 of ejection-phase 
data_bins_enc$click_sys2_rel <- (data_bins_enc$click_sys2/120) / ((0.5 * data_bins_enc$syspat)/data_bins_enc$R_R_s) # second 1/2 of ejection-phase

# whole ejection-phase
data_bins_enc$click_lvet_rel <- ((data_bins_enc$click_lvet)/120)/((data_bins_enc$syspat)/data_bins_enc$R_R_s) # all clicks in lvet (sys1+sys2) / lvetlength (syspat) 

# total electromechanical systole (pre-ejection + ejection phase)
data_bins_enc$click_allsys_rel <- ((data_bins_enc$click_allsys)/120)/((data_bins_enc$pep + data_bins_enc$syspat)/data_bins_enc$R_R_s)  # all clicks in sys (pep+sys1+sys2) / syslength (pep + syspat)

#--------------------------------------------------------------------------
## DIASTOLE
# each diastolic phase (whole diastole divided in 4 parts)
data_bins_enc$click_dias1_rel <- (data_bins_enc$click_dias1/120) / ((0.25* data_bins_enc$diaspat)/data_bins_enc$R_R_s) 
data_bins_enc$click_dias2_rel <- (data_bins_enc$click_dias2/120) / ((0.25* data_bins_enc$diaspat)/data_bins_enc$R_R_s) 
data_bins_enc$click_dias3_rel <- (data_bins_enc$click_dias3/120) / ((0.25* data_bins_enc$diaspat)/data_bins_enc$R_R_s) 
data_bins_enc$click_dias4_rel <- (data_bins_enc$click_dias4/120) / ((0.25* data_bins_enc$diaspat)/data_bins_enc$R_R_s)  

# total diastole
data_bins_enc$click_alldias_rel <- ((data_bins_enc$click_alldias)/120) / (data_bins_enc$diaspat/data_bins_enc$R_R_s) # all clicks in dias (dias1+dias2+dias3+dias4) / diaslength (diaspat)
```


#### 1.B.2 Run analysis: Paired t-test

* Group-level analysis: normalized systolic and diastolic ratios are tested against each other (two-sided paired t-test)
* The systolic (lvet, i.e. left-ventrcular ejection-period) ratio is significantly bigger than the diastolic ratio. 
```{r enc paired ttest}
#--------------------------------------------------------------------------
# paired t-test
t.test(data_bins_enc$click_lvet_rel, data_bins_enc$click_alldias_rel, paired = T) # *
cohen.d(data_bins_enc$click_lvet_rel, data_bins_enc$click_alldias_rel, paired = T)

# test for normality
shapiro.test(data_bins_enc$click_lvet_rel) # n.s.
shapiro.test(data_bins_enc$click_alldias_rel) # n.s.
# distribution of data not significantly different from normal distribution
#--------------------------------------------------------------------------
```


#### 1.B.3. Plot results with ggplot (Fig. 2b)

a) Prepare dataframes: melt and cast dataframes

* phase (lvet, dias = variable) ~ respective ratios (= value)
* get overall mean, and standard deviation of systolic and diastolic ratios
```{r enc  prep dataframes}
#--------------------------------------------------------------------------
# prepare long df m_lvetclick (relative clickrates for ejection-phase vs whole diastole)
# melt data_bins_enc showing phase (lvet, dias = variable) ~ respective ratios (=value)
m_lvetclick <- melt(data_bins_enc, id = "vp", measure = c("click_lvet_rel", "click_alldias_rel"))
colnames(m_lvetclick) <- c("vp", "phase", "rel_clickrate")

# cast m_lvetclick: for each phase(lvet, dias=variable) show ratio(=value) mean, sd, length, se
c_lvetclick <- cast(m_lvetclick, phase ~ ., c(mean, sd, length, se, se_up, se_down), value = "rel_clickrate")

#--------------------------------------------------------------------------
```


b) Create column for colouring different cardiac phases in ggplot (systole, diastole, non-defined phase)
```{r colour column}
#--------------------------------------------------------------------------
## COMPARE SYSTOLE(LVET) AND DIASTOLE

# compare click rates with phase rates (click rate - phase rate)
# systole
data_bins_enc$diff_plvet <- (data_bins_enc$click_lvet/120) - data_bins_enc$prop_syspat_RR # click rate systole - prop systole
data_bins_enc$check_plvet <- (sign(data_bins_enc$diff_plvet)) # check whether click rate (1) or phase rate (-1) is higher

# diastole
data_bins_enc$diff_pdias <- (data_bins_enc$click_alldias/120) - data_bins_enc$prop_alldias_RR # click rate dias - prop dias
data_bins_enc$check_pdias <- (sign(data_bins_enc$diff_pdias))

# create column col to prepare coloring each quadrant (q1, q2, q3,q4) of ggplot
for (i in (1:length(data_bins_enc$vp))) {
  if(as.numeric(data_bins_enc$check_pdias[i] > 0 & data_bins_enc$check_plvet[i] < 0)) { #q1 (left upper, overproportional diastolic ratio)
    data_bins_enc$col[i] <- 1
  } else if(data_bins_enc$check_pdias[i] > 0 & data_bins_enc$check_plvet[i] > 0) { #q2 (right upper, overproportional diastolic ratio)
    data_bins_enc$col[i] <- 2
  } else if (data_bins_enc$check_pdias[i] < 0 & data_bins_enc$check_plvet[i] > 0) { #q3 (right lower, overproportional systolic ratio)
    data_bins_enc$col[i] <- 3
  } else {
    data_bins_enc$col[i] <- 2 #q4 (left lower, non-defined)
  }
  
}
data_bins_enc$col <- factor(data_bins_enc$col)
#--------------------------------------------------------------------------
```


c) Scatter plot for systolic vs. diastolic ratio

**Figure 2.b**:

* Systolic vs. diastolic ratio for each participant
* Dashed lines: number of picture onsets that would be expected if they were uniformly distributed (resulting in a ratio = 1)
* Orange: participants who preferred to prompt pictures in systole (systolic ratio >1, diastolic <1)
* Blue: participants who preferred to prompt pictures in diastole (diastolic ratio >1, systolic <1)
* Grey: participants who did not show a preference in any of the two defined phases
```{r ggplot relative ratios}
#--------------------------------------------------------------------------
par(mar=c(0,0,0,0))
# pdf(file = paste(path_figures, "fig_sysdias1",".pdf",sep=""),width=4.5,height=4.5)

# scatterplot relative click rates for total systole (x) vs. total diastole (y)
fig_sysdias <- ggplot(data_bins_enc) +
  geom_hline(aes(yintercept = 1), size=0.5, linetype="dashed")+ 
  geom_vline(aes(xintercept = 1), size=0.5, linetype="dashed")+
  geom_point(size=3, aes(x=click_lvet_rel, y=click_alldias_rel, col = col, shape = col))+ #click_alldias_rel
  scale_colour_manual(values=c(defmedblue, defgrey, deforange, defgrey)) +
  geom_point(data = c_lvetclick, colour = "black", aes(x=mean[1], y=mean[2]), size = 3) +
  geom_errorbarh(data = c_lvetclick, colour = "black", aes(x = mean[1], xmin = se_down[1], xmax = se_up[1], y = mean[2]),  size=0.5, height = 0.005) +
  geom_errorbar(data = c_lvetclick, colour = "black", aes(ymin = se_down[2], ymax = se_up[2], x = mean[1]),  size=0.5, width = 0.005) +
  coord_cartesian(xlim = c(0.75, 1.4), ylim = c(0.75, 1.4)) +
  labs(x = "Systolic ratio", y = "Diastolic ratio") +
  mytheme 

fig_sysdias

# dev.off()

#--------------------------------------------------------------------------
```




## 2. RECOGNITION - Cardiac influence on recognition memory

* Adapt dataframe to clean participant list
```{r rec analysis absolute}
#--------------------------------------------------------------------------
log_encode <- log_encode[log_encode$vp %in% inc_clean,]
#--------------------------------------------------------------------------
```


### 2.A. CIRCULAR ANALYSIS
* Test distribution of memory probes (hits, misses) relative to their cardiac time point in encoding against circular uniform distribution (for each valence: neg, neu, pos)


#### 2.A.1. Exemplary participant-level analysis of hits, misses

* Exemplary stimulus distribution of picture onsets across the cardiac cycle (Rpeak = 0) for hits, misses
* Circular plots (for visualization purposes, not included in manuscript):
```{r test HIT, MISS against uniform for one vp}
#--------------------------------------------------------------------------
# first-level analysis: exemplary participant
circ_click_mem("inc25", det = "hit_miss", plot1 =T, ray1  = T) # distribution of memory probes (= hits and misses)
circ_click_mem("inc25", det = "HIT", plot1 =T, ray1  = T) # distribution of hits
circ_click_mem("inc25", det = "MISS", plot1 =T, ray1  = T) # distribution of misses
#--------------------------------------------------------------------------
```


#### 2.A.2. Group-level analysis of hits, misses 

* Distribution of participants' stimulus onset means (encoding) across the cardiac cycle for hits and misses
* Circular plots (for visualization purposes, not included in manuscript):
```{r test HIT, MISS against uniform group-level}
#--------------------------------------------------------------------------
# second-level analysis: HITs
# pdf(file = paste(path_figures, "circ_det_hit.pdf", sep=""), width=5, height=5)
circ_click_mem(inc_clean_cutSignmem_ray, det = "HIT", plot2 =T, ray2 = T) 
# dev.off()

# second-level analysis: MISSes
# pdf(file = paste(path_figures, "circ_det_miss_big.pdf", sep=""), width=5, height=5)
circ_click_mem(inc_clean_cutSignmem_ray, det = "MISS", plot2 =T, ray2 = T)
# dev.off()
#--------------------------------------------------------------------------
```



### 2.B. BINARY ANALYSIS (GLMM): 

* Analyse influence of cardiac phase (systole, diastole) and valence (negative, neutral, positive) on recognition memory.

* GLMM for binomial data with subject as random factor
* Dependent variable: recognition memory (coding: 0 = miss, 1 = hit) = bivariate dependent variable

* Independent within-subject variables:
  - Cardiac phase: 0 = diastole, 1 = systole
  - Three valence levels (positive, negative, neutral), contrast-coded with neutral valence as baseline condition: positive-neutral, negative-neutral


#### 2.B.1. Prepare dataframe d

* Prepare dataframe d (memory probes)
```{r regression model prepare dataframe}
#--------------------------------------------------------------------------
## adapt dataframe to clean participant list
data <- log_encode[log_encode$vp %in% inc_clean,]

# remove all trials with items that were not presented during encoding (include only old pictures)
idx <- which(is.na(data$answer)==FALSE) # select only rows where answer is not NA (NA for new pictures)
d <- data[idx,] # df for memory probes 

# create factors
d$vp <- as.factor(d$vp)
d$stimnum <- as.factor(d$stimnum)

#--------------------------------------------------------------------------
# Valence: define contrast - set neutral valence as reference condition
d$valence2 <- d$valence
contrasts(d$valence2) <- contr.treatment(3,base=1) # contrast with neutral as baseline -> 3 factor levels, base = neutral (level1)

#--------------------------------------------------------------------------
## Add individual arousal ratings (z-transformed)
d$iar <- (d$rate_arousal) # as.factor
d$iarz <- (d$iar - mean(d$iar))/sd(d$iar) # z-transform
# hist(d$iar)

## Individual valence ratings (z-transformed)
d$ivr <- (d$rate_valence) # as.factor
d$ivrz <- (d$ivr - mean(d$ivr))/sd(d$ivr) # z-transform
# hist(d$ivr)
#--------------------------------------------------------------------------
```



#### 2.B.2. Compute overall mean recognition performance

 * Mean recognition performance (detection rate) for negative, neutral, positive old pictures 
```{r mean recognition performance}
#--------------------------------------------------------------------------
# get mean recognition performance for each participant (for each valence)
m1 <- melt(d,id=c("valence","vp"),measure=c("answer"))
c1 <- cast(m1,valence + vp ~ variable, mean) # mean -> c(mean))

#mean recognition performance over all participants for each valence
m2 <- melt(c1,id=c("valence"),measure=c("answer"))
c2 <- cast(m2, valence ~ variable, c(mean, sd))
#--------------------------------------------------------------------------
```



#### 2.B.3. Run model m0, m1 (Table 1)

* m0: recognition memory ~ 1 + (1|subject) (null model)
* m1: recognition memory ~ valence + (1|subject)
* Valence: contrast-coded with neutral as baseline (positive-neutral, negative-neutral)
* see also **Table 1**:
```{r GLMM m0, m1}
#--------------------------------------------------------------------------
# Null model
m0 <- glmer(answer ~ 1 + (1|vp),data=d,family="binomial") # null model

# run model for valence 
m1 <- glmer(answer ~ valence2 + (1|vp),data=d,family="binomial") # valence

# check output of model
summary(m1) 
#--------------------------------------------------------------------------
```


* Plot model prediction (for visualization purposes, not included in manuscript):
```{r GLMM m1 plot}
#--------------------------------------------------------------------------
## 1. overall model for valence:
# m1: memory performance as function of valence (m1)
d$pred_logit <- predict(m1) # add model fits to df
d$pred_prob  <- exp(d$pred_logit)/(1+exp(d$pred_logit))

#val: plot(d$answer,d$pred_prob)
pred_val <- ggplot(d,aes(x=valence2,y=pred_prob))+ 
  scale_colour_manual(values=c(defmedblue, deforange)) +
  geom_boxplot()+
  labs(x = "Valence", y = "Predicted probability") +
  mytheme
pred_val
#--------------------------------------------------------------------------
```


* Likelhood ratio test m1 vs. m0 
* Check for significance of m1 
```{r LRT m1}
#--------------------------------------------------------------------------
# Likelihood ratio test (LRT) m1 vs. m0
anova (m1, m0)
#--------------------------------------------------------------------------
```



#### 2.B.4. Run model m2 (Table 1)

* m2: recognition memory ~ valence * cardiac phase + (1|subject)  (main model of interest)
* Prepare dataframe d1
* see also **Table 1**:
```{r GLMM m2}
#--------------------------------------------------------------------------
# adapt dataframe: select only trials from individual systole, diastole
# phase: set diastole == 0 as reference condition, systole = 1
d1 <- d[(d$click_bin=="click_lvet" | d$click_bin=="click_dias"),] # select only clicks in systole (lvet) and diastole (dias)
d1$ds <- as.factor(ifelse(d1$click_bin=="click_dias",0,1)) # set dias 0, lvet 1 (factor with 2 levels)

#--------------------------------------------------------------------------
# run model for valence * cardiac phase 
m2 <- glmer(answer ~ valence2*ds + (1|vp),data=d1,family="binomial") # valence * cardiac phase

# check output of models
summary(m2) 
#--------------------------------------------------------------------------
```


* Plot model prediction (for visualization purposes, not included in manuscript):
```{r GLMM m2 plot}
#--------------------------------------------------------------------------
# m1: compute predictions for model valence * cardiac phase
d1$pred_logit <- predict(m2) # add model fits to df
d1$pred_prob  <- exp(d1$pred_logit)/(1+exp(d1$pred_logit))

#valds: plot(d$answer,d$pred_prob)
pred_valds <- ggplot(d1,aes(x=valence2,y=pred_prob,colour=click_bin))+
  scale_colour_manual(values=c(defmedblue, deforange)) + # blue: diastole, orange: systole
  geom_boxplot()+
  labs(x = "Valence * Cardiac phase", y = "Predicted probability") #+
  #mytheme
pred_valds
#--------------------------------------------------------------------------
```


* Likelihood ratio test m2 vs. m1
* Check for significance of m2 
```{r LRT m2}
#--------------------------------------------------------------------------
# m1 with adapted dataframe (only to contain systolic, diastolic pictures)
m1_ed <- glmer(answer~ valence2 + (1|vp),data=d1,family="binomial") # valence, including only systolic and diastolic trials

# Likelihood ratio test (LRT) m1 vs. m0
anova (m1_ed, m2)
#--------------------------------------------------------------------------
```


#### 2.B.5. Refine GLMM analyses (cf. Revision: Reviewer 2, comment #2)

#### 1) Add picture as random factor

* Add picture as random factor
* Compute new models: 
* m0_p: memory ~ 1 + (1|subject) + (1|pic)
* m1_p: memory ~ valence + (1|subject) + (1|pic)
* m2_p: memory ~ valence * cardiac phase + (1|subject) + (1|pic)
```{r add random factor pic}
#--------------------------------------------------------------------------
# including picture as random factor to existing models
m0_p <- glmer(answer ~ 1 + (1|vp) + (1|stimnum),data=d,family="binomial")
m1_p <- glmer(answer ~ valence + (1|vp) + (1|stimnum),data=d,family="binomial") 
m2_p <- glmer(answer ~ valence * ds + (1|vp) + (1|stimnum),data=d1,family="binomial") 
summary(m0_p)
#--------------------------------------------------------------------------
```


* Lilkelihood ratio tests against previous models (without picture as random factor)
```{r LRT random factor pic}
#--------------------------------------------------------------------------
# Likelihood ratio test (LRT) 
anova(m0, m0_p)
anova(m1, m1_p)
anova(m2, m2_p)
#--------------------------------------------------------------------------
```



##### 2) Add individual ratings as fixed effect

* Compute new models to analyse interaction of ind. ratings with cardiac phase
* m3: memory ~ ind.arousal * cardiac phase + (1|subject) 
* m4: memory ~ ind.valence * cardiac phase + (1|subject)
```{r add fixed effect individual ratings}
#--------------------------------------------------------------------------
# check models with individual ratings
m3 <- glmer(answer ~ iarz * ds + (1|vp),data=d1,family="binomial") # iarz*ds
m4 <- glmer(answer ~ ivrz * ds + (1|vp),data=d1,family="binomial") # ivrz*ds
summary(m4)
```


* Lilkelihood ratio tests against m2 (valence as fixes effect)
```{r LRT fixed effect individual ratings}
#--------------------------------------------------------------------------
# LRT
anova(m2, m3) # n.s.
anova(m2, m4) # *
#--------------------------------------------------------------------------
```



# SUPPLEMENTARY ANALYSES

## 1. Correlation of self-paced sampling with inter-individual differences (Revision: Reviewer 1, comment #1)

### 1.A. Prepare dataframe and include additional variables (inter-individual differences)

* Group-level correlation of inter-individual differences (IA, RMSSD, STAI) with "phase-associated stimulus prompting" (i.e., phase ratios click_lvet_rel and click_alldias_rel)

* Prepare variables:
1. Heart rate variability (rmssdl: log-transformed to mitigate skewedness and centred to the mean) 
2. Trait Anxiety (staiz: z-transformed)
3. Interoceptive Accuracy (IAz: z-transformed)

```{r enc correl df intdiff_phase}
#--------------------------------------------------------------------------
## Create df with relevant variables
intdiff_phase <- data_bins_enc[,c("vp", "click_lvet_rel", "click_alldias_rel", "IA_score", "stai_sum_score", "rmssd_rest_score", "HR_1perMin")]

## Transform interindividual variables:
# 1. HRV (rmssd): log-transform of heart rate variability
intdiff_phase$rmssdl <- log(intdiff_phase$rmssd_rest_score) - mean(log(intdiff_phase$rmssd_rest_score)) # centered by mean

# 2. STAI: z-Transform of trait anxiety
intdiff_phase$staiz <- (intdiff_phase$stai_sum_score - mean(intdiff_phase$stai_sum_score))/sd(intdiff_phase$stai_sum_score) 

# 3. IA: z-Transform of interoceptive accuracy

# Remove 2 sujbects without IA measure (intdiff_phase1)
idx1 <- which(is.na(intdiff_phase$IA_score)==FALSE)
intdiff_phase1 <- intdiff_phase[idx1,]
intdiff_phase1$iaz <- (intdiff_phase1$IA_score - mean(intdiff_phase1$IA_score))/sd(intdiff_phase1$IA_score)

#--------------------------------------------------------------------------
```


### 1.B. Run correlations

* Compute bivariate correlation between individual (systolic, diastolic) ratios of picture onsets and covariates
```{r enc correl}
#--------------------------------------------------------------------------
## Analyze  correlations

# 1. HRV (rmssd rest): 
cor.test(intdiff_phase$rmssdl,intdiff_phase$click_lvet_rel) # sys - n.s.
cor.test(intdiff_phase$rmssdl,intdiff_phase$click_alldias_rel) # dias - n.s.

# 2. STAI:
cor.test(intdiff_phase$staiz,intdiff_phase$click_lvet_rel) # sys - non-sign. trend
cor.test(intdiff_phase$staiz,intdiff_phase$click_alldias_rel) # dias - n.s.

# 3. IA
cor.test(intdiff_phase1$iaz,intdiff_phase1$click_lvet_rel) # sys - n.s.
cor.test(intdiff_phase1$iaz,intdiff_phase1$click_alldias_rel) # dias - n.s.
#--------------------------------------------------------------------------
```


### 1.C. Plot correlations (Fig. 3)

* see also *Figure 3**:
```{r enc correl plot}
#--------------------------------------------------------------------------
# double plots (sys and dias ratios in one plot)
# IA
cor_sysdias_ia <- ggplot(intdiff_phase1,aes(x=iaz,y=click_lvet_rel))+
  geom_smooth(method = "lm", se = T, colour = deforange, size=0.8) + 
  geom_point(colour = deforange, shape = 15, size = 2)+
  geom_smooth(aes(x=iaz,y=click_alldias_rel), method = "lm", se = T, colour = defmedblue, size=0.8) + 
  geom_point(aes(x=iaz,y=click_alldias_rel), colour = defmedblue,  size = 2)+
  labs(x = "Interoceptive accuracy (z-transformed)", y = "Individual ratios") +
  mytheme
cor_sysdias_ia

# STAI
cor_sysdias_stai <- ggplot(intdiff_phase,aes(x=staiz,y=click_lvet_rel))+
  geom_smooth(method = "lm", se = T, colour = deforange, size=0.8) + 
  geom_point(colour = deforange, shape = 15, size = 2)+
  geom_smooth(aes(x=staiz,y=click_alldias_rel), method = "lm", se = T, colour = defmedblue, size=0.8) + 
  geom_point(aes(x=staiz,y=click_alldias_rel), colour = defmedblue,  size = 2)+
  labs(x = "Trait anxiety (z-transformed)", y = "Individual ratios") +
  mytheme
cor_sysdias_stai

# HRV
cor_sysdias_hrv <- ggplot(intdiff_phase,aes(x=rmssdl,y=click_lvet_rel))+
  geom_smooth(method = "lm", se = T, colour = deforange, size=0.8) + 
  geom_point(colour = deforange, shape = 15, size = 2)+
  geom_smooth(aes(x=rmssdl,y=click_alldias_rel), method = "lm", se = T, colour = defmedblue, size=0.8) + 
  geom_point(aes(x=rmssdl,y=click_alldias_rel), colour = defmedblue,  size = 2)+
  labs(x = "rMSSD (log-transformed)", y = "Individual ratios") +
  mytheme
cor_sysdias_hrv

#--------------------------------------------------------------------------
# Triple plot
triple_cor_sysdias <- plot_grid(cor_sysdias_ia, cor_sysdias_stai, cor_sysdias_hrv, ncol=3, align = "h", labels = c("a", "b", "c"), label_size = 14)

#--------------------------------------------------------------------------
# pdf(file = paste(path_figures, "triple_cor_sysdias", ".pdf", sep=""), width=10, height=3.5)
triple_cor_sysdias
# dev.off()
#--------------------------------------------------------------------------
```


## 2. Correlation of recognition memory with inter-individual differences

### 2.A. Prepare dataframe and include additional variables (inter-individual differences)

* Group-level correlation of inter-individual differences (IA, RMSSD, STAI) with recognition memory performance

* Prepare variables:
1. Heart rate variability (rmssdl: log-transformed to mitigate skewedness and centred to the mean) 
2. Trait Anxiety (staiz: z-transformed)
3. Interoceptive accuracy (IAz: z-transformed)

```{r corr rec covariates prep}
#--------------------------------------------------------------------------
# prepare dataframe
d <- data[idx,] # df for memory probes 

# add covariates
# 1. HRV (rmssd): log-transform of heart rate variability
d$rmssd <- d$rmssd_rest
d$rmssdl <- log(d$rmssd) - mean(log(d$rmssd)) # centered by mean
# hist(d$rmssdl)

# 2. STAI: z-Transform of trait anxiety
d$staiz <- (d$stai_sum - mean(d$stai_sum))/sd(d$stai_sum) 
#hist(d$staiz)

# 3. IA: z-Transform of interoceptive accuracy
# remove 2 sujbects without IA measure (d1)
idx1 <- which(is.na(d$IA)==FALSE)
d1 <- d[idx1,]
d1$IAz <- (d1$IA - mean(d1$IA))/sd(d1$IA)
#--------------------------------------------------------------------------
```


### 2.B. Run correlations

* Compute bivariate correlation between mean recognition performance and covariates
```{r corr rec covariates run}
#--------------------------------------------------------------------------
# get mean performance
m0 <- melt(d,id=c("vp"),measure=c("answer"))
c0 <- cast(m0, vp ~ variable, mean)

# d1: adapted for IA
m01 <- melt(d1,id=c("vp"),measure=c("answer"))
c01 <- cast(m01, vp ~ variable, mean)

#--------------------------------------------------------------------------
# 1. get individual rmssdl
m1 <- melt(d,id=c("vp"),measure=c("rmssdl"))
c1 <- cast(m1,vp ~ variable, mean)

# 2. get individual staiz
m2 <- melt(d,id=c("vp"),measure=c("staiz"))
c2 <- cast(m2,vp ~ variable,mean)

# 3. get individual IA (with d1)
m3 <- melt(d1,id=c("vp"),measure=c("IAz"))
c3 <- cast(m3,vp ~ variable,mean)

#--------------------------------------------------------------------------
# compute correlations
# 1. rmssdl
cor.test(c1$rmssdl,c0$answer)
res1 <- lm(c0$answer~c1$rmssdl)
summary(res1)

# 2. staiz
cor.test(c2$staiz,c0$answer)
res2 <- lm(c0$answer~c2$staiz)
summary(res2)

# 3. IAz
cor.test(c3$IAz,c01$answer)
res3 <- lm(c01$answer~c3$IAz)
summary(res3)
#--------------------------------------------------------------------------
```


### 2.C. Plot correlations (Fig. 4)

* see also *Figure 4**:
```{r corr rec covariates plot}
#--------------------------------------------------------------------------
par(mar=c(0,0,0,0))
# 1. rmssdl
# join c1, c2
c0c1 <- left_join(c0, c1, by = c('vp'))

# ggplot
# pdf(file = paste(path_figures, "cor_perfhrv", ".pdf", sep=""), width=5.5, height=5)
cor_perfhrv <- ggplot(c0c1,aes(x=rmssdl,y=answer))+
  geom_smooth(method = "lm", se = T, colour = "black", size=0.5) + 
  geom_point()+
  labs(x = "rMSSD (log-transformed)", y = "Mean recognition performance") +
  mytheme
cor_perfhrv
# dev.off()

#--------------------------------------------------------------------------
# 2. staiz
c0c2 <- left_join(c0, c2, by = c('vp'))

# ggplot
# pdf(file = paste(path_figures, "cor_perfstaiz", ".pdf", sep=""), width=5.5, height=5)
cor_perfstaiz <- ggplot(c0c2,aes(x=staiz,y=answer))+
  geom_smooth(method = "lm", se = T, colour = "black", size=0.5) + 
  geom_point()+
  labs(x = "Trait anxiety (z-transformed)", y = "Mean recognition performance") +
  mytheme
cor_perfstaiz 
# dev.off()

#--------------------------------------------------------------------------
# 3. IAz
c01c3 <- left_join(c01, c3, by = c('vp'))

# ggplot
# pdf(file = paste(path_figures, "cor_perfiaz", ".pdf", sep=""), width=5.5, height=5)
cor_perfiaz <- ggplot(c01c3,aes(x=IAz,y=answer))+
  geom_smooth(method = "lm", se = T, colour = "black", size=0.5) + 
  geom_point()+
  labs(x = "Interoceptive Accuracy (z-transformed)", y = "Mean recognition performance") +
  mytheme
cor_perfiaz 
# dev.off()

#--------------------------------------------------------------------------
pdf(file = paste(path_figures, "triple_cor_update", ".pdf", sep=""), width=10, height=3.5)
triple_cor <- plot_grid(cor_perfiaz, cor_perfstaiz, cor_perfhrv, ncol=3, align = "h", labels = c("a", "b", "c"), label_size = 14)
triple_cor
dev.off()
#--------------------------------------------------------------------------
```



## 3. Analyse ratings: Subjective perception of picture emotionality (normative vs. individual ratings)

### 3.A. Normative and individual means of picture ratings for arousal and valence

* Compare individual vs. normative ratings (mean, sd, se)
```{r stimnum ratings}
#----------------------------------------------------------------------------
## 1. AROUSAL: melt arousal ratings - melt rate_va
m_rate_a <- melt(rate_va, id = c("stimnum", "valence"), measure = c("rate_arousal", "norms_arousal"))

# cast m_rate_a: valence (rows) ~ mean individual rating (cols)
c_rate_a <- cast(m_rate_a, valence ~ variable, c(mean, sd, length, se)) #   mean, sd, length, se for each valence

# mean individual and normative ratings
c_rat_a_all <- cast(m_rate_a, . ~ variable, c(mean, sd, length, se)) # over all valences

## 2. VALENCE: melt valence ratings - melt rate_v
m_rate_v <- melt(rate_va, id = c("stimnum", "valence"), measure = c("rate_valence", "norms_valence"))

# cast m_rate_v: valence (rows) ~ mean individual rating (cols)
c_rate_v <- cast(m_rate_v, valence ~ variable, c(mean, sd, length, se)) # mean, sd, length, se for each valence

# mean individual and normative ratings
c_rat_v_all <- cast(m_rate_v, . ~ variable, c(mean, sd, length, se)) # over all valences
#----------------------------------------------------------------------------
```


### 3.B. Run tests to compare normative vs. individual ratings

* 1. Run mixed-design ANOVAs to test ratings across rating category (normative, individual) and valence
* 2. Run two-sided paired ttests for normative vs. individual ratings across each valence level
```{r stimnum ratings run tests}
#----------------------------------------------------------------------------
## 1. Run ANOVA:
# for each valence level: run anova to test for diff. in mean ratings between individual and normative picture ratings

# 1.1. AROUSAL ratings: rating value ~ valence * rating category (individual vs. norms)
aov_a <- aov((value) ~ valence * variable + Error(stimnum/variable), data=m_rate_a) 
summary(aov_a)


# 1.2. VALENCE ratings
aov_v <- aov(log(value) ~ valence * variable + Error(stimnum/variable), data=m_rate_v)
summary(aov_v)

#----------------------------------------------------------------------------
## 2. Run two-sided t-tests across valence levels

# run t-tests for each valence subset
# subsets for each valence
sub_neg <- rate_va[rate_va$valence == "negativ",]
sub_pos <- rate_va[rate_va$valence == "positiv",]
sub_neu <- rate_va[rate_va$valence == "neutral",]

## 2.1. AROUSAL
# a) Neutral pictures
a_neu <- t.test(sub_neu$norms_arousal,sub_neu$rate_arousal, paired = T, alternative = "two.sided") # ***
cohen.d(sub_neu$norms_arousal,sub_neu$rate_arousal)
cor.test(sub_neu$norms_arousal,sub_neu$rate_arousal) # ***

# b) Positive pictures
a_pos <- t.test(sub_pos$norms_arousal,sub_pos$rate_arousal, paired = T, alternative = "two.sided") # ***
cohen.d(sub_pos$norms_arousal,sub_pos$rate_arousal)
cor.test(sub_pos$norms_arousal,sub_pos$rate_arousal) # ***

# c) Negative pictures
a_neg <- t.test(sub_neg$norms_arousal,sub_neg$rate_arousal, paired = T, alternative = "two.sided") # ***
cohen.d(sub_neg$norms_arousal,sub_neg$rate_arousal)
cor.test(sub_neg$norms_arousal,sub_neg$rate_arousal) # ***

# adjust p-values
p_aro <- c(a_neu$p.value, a_pos$p.value, a_neg$p.value)
p.adjust(p_aro, method = "bonferroni")

#----------------------------------------------------------------------------
## 3. compute difference in norms arousal ratings: btw. negative and positive pictures (described in methods)
# norms ratings
t.test(sub_neg$norms_arousal,sub_pos$norms_arousal, alternative = "two.sided") # n.s. difference btw norms arousal (neg vs pos)
cohen.d(sub_neg$norms_arousal,sub_pos$norms_arousal)

# individual ratings
t.test(sub_neg$rate_arousal,sub_pos$rate_arousal, alternative = "two.sided") # *** diff. btw. rated arousal (neg vs pos)
cohen.d(sub_neg$rate_arousal,sub_pos$rate_arousal)
#----------------------------------------------------------------------------
```


### 3.C. Plot normative vs. individual ratings (Fig. 5)

1. Plot Valence ratings
2. Plot Arousal ratings

* see **Figure 5**:
```{r stimnum ratings plot}
#----------------------------------------------------------------------------
# 1. Valence ratings
cor_val <- ggplot(rate_va) +
  geom_abline(slope=1, size=0.2358491) +
  geom_point(size=1, aes(norms_valence, rate_valence), colour = defgrey) + 
  geom_point(data = c_rate_v, colour = "black", aes(x=norms_valence_mean, y=rate_valence_mean), size = 1.5) +
  geom_errorbarh(data = c_rate_v, colour = "black", aes(x = norms_valence_mean, xmin = norms_valence_mean - norms_valence_se, xmax = norms_valence_mean + norms_valence_se, y = rate_valence_mean),  size=0.2358491, height = 0.1) +
  geom_errorbar(data = c_rate_v, colour = "black", aes(ymin = rate_valence_mean - rate_valence_se, ymax = rate_valence_mean + rate_valence_se, x = norms_valence_mean),  size=0.2358491, width=0.1) +
  facet_wrap(~valence)+
  #geom_smooth(method = "lm", se = T, colour = "black", size=0.2358491) + 
  mytheme + #mytheme #theme_classic() +
  scale_x_continuous(name = "normative rating - valence",
                           breaks = seq(1, 8, 2),
                           limits=c(1, 8)) +
  scale_y_continuous(name = "mean individual rating - valence",
                     breaks = seq(1, 8, 1),
                           limits=c(1, 8)) 
cor_val

# ggsave("fig_corval.pdf", plot = cor_val, device = "pdf", path = path_figures,
#   dpi = 300, width = 15, height = 6, units = "cm", limitsize = T)

#----------------------------------------------------------------------------
# 2. Arousal ratings
cor_aro <- ggplot(rate_va) +
  geom_abline(slope=1, size=0.2358491) +
  geom_point(size=1, aes(norms_arousal, rate_arousal), colour = defgrey) + #shape=15
  geom_point(data = c_rate_a, colour = "black", aes(x=norms_arousal_mean, y=rate_arousal_mean), size = 1.5) +
  geom_errorbarh(data = c_rate_a, colour = "black", aes(x = norms_arousal_mean, xmin = norms_arousal_mean - norms_arousal_se, xmax = norms_arousal_mean + norms_arousal_se, y = rate_arousal_mean),  size=0.2358491, height = 0.1) +
  geom_errorbar(data = c_rate_a, colour = "black", aes(ymin = rate_arousal_mean - rate_arousal_se, ymax = rate_arousal_mean + rate_arousal_se, x = norms_arousal_mean),  size=0.2358491, width=0.1) +
  facet_wrap(~valence)+
  #geom_smooth(method = "lm", se = T, colour = "black", size=0.2358491) + 
  mytheme + #mytheme #theme_classic() +
  scale_x_continuous(name = "normative rating - arousal",
                           breaks = seq(2, 7, 1),
                           limits=c(2, 7)) +
  scale_y_continuous(name = "mean individual rating - arousal",
                     breaks = seq(2, 7, 1),
                           limits=c(2, 7)) 
cor_aro

# ggsave("fig_coraro.pdf", plot = cor_aro, device = "pdf", path = path_figures,
#   dpi = 300, width = 15, height = 6, units = "cm", limitsize = T)

#----------------------------------------------------------------------------
# pdf(file = paste(path_figures, "dbl_cor_rate", ".pdf", sep=""), width=8, height=7)
# dbl_cor_rate <- plot_grid(cor_val, cor_val, nrow =2, align = "v", labels = c("a", "b"), label_size = 14)
# dbl_cor_rate
# dev.off()
#----------------------------------------------------------------------------
```



## 4. Test match of picture features (EmoPicS)

* Load dataframe
```{r picture match load df}
#----------------------------------------------------------------------------
load(paste(path_dataframes,"emopics_match.RData", sep="")) # load df

## Mean values image statistics
melt_match <- melt(emopics_match, id= c("valence"), measure = c("luminance", "contrast",  "complexity", "pcount", "group", "closeup", "eyecont"))
mean_match <- cast(melt_match, formula = valence ~ variable, mean) # means
#----------------------------------------------------------------------------
```


### 4.A. Test match of physical picture features

* 1. Luminance - *
* 2. Contrast - n.s.
* 3. Complexity - n.s.
```{r picture match physical}
#----------------------------------------------------------------------------
## 1.Luminance *
t_lum <- pairwise.t.test(emopics_match$luminance, emopics_match$valence, p.adjust.method = "bonferroni") # * neg.-pos.

# test positive vs. negative
t.test(emopics_match$luminance[emopics_match$valence == "positiv"], emopics_match$luminance[emopics_match$valence == "negativ"])

cohen.d(emopics_match$luminance[emopics_match$valence == "positiv"], emopics_match$luminance[emopics_match$valence == "negativ"])

# plot luminance
plot_lum <- ggplot(emopics_match) + 
  geom_point(aes(x=valence, y=luminance, col = valence)) +
  geom_boxplot(aes(x=valence, y=luminance))
print(plot_lum)

#----------------------------------------------------------------------------
## 2. Contrast
t_cont <- pairwise.t.test(emopics_match$contrast, emopics_match$valence, p.adjust.method = "bonferroni")

#----------------------------------------------------------------------------
## 3. Complexity
t_compl <- pairwise.t.test(emopics_match$complexity, emopics_match$valence, p.adjust.method = "bonferroni")

#----------------------------------------------------------------------------
```



### 4.B. Test match of high-level picture features

* 1. Person count - n.s.
* 2. Social interaction - n.s.
* 3. Close-up - n.s.
* 4. Eye contact - n.s.

```{r picture match social}
#----------------------------------------------------------------------------
## 1. Person count
sum_pcount_neu <- sum(emopics_match$pcount[emopics_match$valence == "neutral"]) # 120/60
sum_pcount_pos <- sum(emopics_match$pcount[emopics_match$valence == "positiv"]) # 143/60
sum_pcount_neg <- sum(emopics_match$pcount[emopics_match$valence == "negativ"]) # 123/60

chisq.test(c(sum_pcount_neu, sum_pcount_pos, sum_pcount_neg)) # n.s.

#----------------------------------------------------------------------------
# 2. Social interaction / group 
sum_group_neu <- sum(emopics_match$group[emopics_match$valence == "neutral"])  # 24
sum_group_pos <- sum(emopics_match$group[emopics_match$valence == "positiv"])  # 39 
sum_group_neg <- sum(emopics_match$group[emopics_match$valence == "negativ"])  # 24

chisq.test(c(sum_group_neu, sum_group_pos, sum_group_neg)) # n.s.


#----------------------------------------------------------------------------
# 3. Closeup 
sum_cl_neu <- sum(emopics_match$closeup[emopics_match$valence == "neutral"])  # 26
sum_cl_pos <- sum(emopics_match$closeup[emopics_match$valence == "positiv"])  # 42
sum_cl_neg <- sum(emopics_match$closeup[emopics_match$valence == "negativ"])  # 34

chisq.test(c(sum_cl_neu, sum_cl_pos, sum_cl_neg)) # n.s.

#----------------------------------------------------------------------------
# 4. Eye contact n.s.
sum_eyec_neu <- sum(emopics_match$eyecont[emopics_match$valence == "neutral"]) # 6
sum_eyec_pos <- sum(emopics_match$eyecont[emopics_match$valence == "positiv"]) # 12 
sum_eyec_neg <- sum(emopics_match$eyecont[emopics_match$valence == "negativ"]) # 9

chisq.test(c(sum_eyec_neu, sum_eyec_pos, sum_eyec_neg)) # n.s.
#----------------------------------------------------------------------------
```



# SUPPLEMENTARY METHODS SECTION

## 1. Correlations of individual systoles and HR (Fig. S1)

### 1.A. Summary of cardiac phases rel. to HR

```{r summary cardiac phases}
#--------------------------------------------------------------------------
# adapt participants to heart analysis -> include participants with high heart rate
data_bins_car <- data_bins[data_bins$vp %in% inc_cuthtn,] # include tachycardic participants (but not HTN)

### summaries of cardiac intervals:
summary(data_bins_car$HR_1perMin) # mean heart-rate in bpm
sd(data_bins_car$HR_1perMin)

summary(data_bins_car$R_R_s) # R-R interval
sd(data_bins_car$R_R_s)

summary(data_bins_car$syspat) # ejection period (EP)
sd(data_bins_car$syspat)

summary(data_bins_car$allsys) # total systole (QT)
sd(data_bins_car$allsys)

summary(data_bins_car$prop_syspat_RR) # proportion of EP in R-R interval
sd(data_bins_car$prop_syspat_RR)

summary(data_bins_car$prop_allsys_RR) # proportion of QT in R-R interval
sd(data_bins_car$prop_allsys_RR)

#--------------------------------------------------------------------------
```


### 1.B. Test correlations 

* 1. Mean HR ~ duration ejection phase (EP)
* 2. Mean HR ~ proportion EP
```{r correlations cardiac parameters}
#--------------------------------------------------------------------------
# 1. Correlation mean HR, duration systolic ejection-phase
cor.test(data_bins_car$HR_1perMin, data_bins_car$syspat) 

# 2. Correlation mean HR, proportion systole (ejection-phase) in total cardiac cycle
cor.test(data_bins_car$HR_1perMin, data_bins_car$prop_syspat_RR) # test correlation duration RR, proportion of sys/RR

#--------------------------------------------------------------------------
```



### 1.C. Plot correlations 

* See also **Supplementary Figure S1**:
```{r plot correlations cardiac parameters}
#--------------------------------------------------------------------------
# 1. Plot Mean HR ~ duration ejection phase (EP)
cor_hrsys <- ggplot(data_bins_car, aes(HR_1perMin, syspat)) + #HR_1perMin, syspat
  geom_point(size=0.8) + #shape=15
  geom_smooth(method = "lm", se = T, colour = "black", size=0.2358491) + 
  mytheme + #mytheme #theme_classic() +
  labs(y = "Systolic ejection-phase (sec) ", x = "Heart rate (bpm)") 
cor_hrsys

# 2. Plot Mean HR ~ proportion EP
cor_hrpropsys <- ggplot(data_bins_car, aes(HR_1perMin, prop_syspat_RR)) + #prop_syspat_RR
  geom_point(size=0.8) + #shape=15
  geom_smooth(method = "lm", se = T, colour = "black", size=0.2358491) + 
  mytheme + #mytheme #theme_classic() +
  labs(x = "Heart rate (bpm)", y = "ejection-phase rel. to R-R") 
cor_hrpropsys

#--------------------------------------------------------------------------
# plot both scatter plots next to each other
double_cor <- plot_grid(cor_hrsys, cor_hrpropsys, ncol=2, align = "h", labels = c("a", "b"), label_size = 12)

# ggsave("double_cor.pdf", plot = double_cor, device = "pdf", path = paste(path_figures,"Manuscript", sep=""),
#   dpi = 300, width = 16, height = 8, units = "cm", limitsize = T) #scale = 1, width = 8.5, height = 5.5, units = "cm",
#--------------------------------------------------------------------------
```



## 2. Ranges and lengths of cardiac phases (Fig. S2)

### 2.A. Summary cardiac phase ranges and lengths

* Overview:
* Systole - ranges and lengths
* Diastole - ranges and lengths
```{r plot cardiac phases}
#--------------------------------------------------------------------------
# df with cardiac phases in ms
check_phase <- data_bins_enc[,c("Rtend_s", "crop", "syspat", "diaspat")]
check_phase <- check_phase * 1000 # transform in ms
colnames(check_phase) <- c("Rtend", "crop", "syspat", "diaspat")
check_phase$vp <- data_bins_enc$vp 

#--------------------------------------------------------------------------
## 1. SYSTOLE (one value per subject -> template approach)

## 1.1. Ranges for each subject (in ms)

# overview start sys 
summary(check_phase$crop) # crop = interval from Rpeak until beginning EP
sd(check_phase$crop)

# overview end sys 
summary(check_phase$Rtend) # Rtend = interval from Rpeak until twave end
sd(check_phase$Rtend)

# overview mid sys
check_phase$mid_sys <- (check_phase$crop + (check_phase$syspat/2)) # Rpeak until mid systole 
summary(check_phase$mid_sys) 

## 1.2. Systole lengths
check_phase$sys_half <- check_phase$syspat/2 # half length systole

# overview length sys (in ms)
summary(check_phase$syspat) # systole duration 
sd(check_phase$syspat)

#--------------------------------------------------------------------------
## 2. DIASTOLE (multiple values per subject)

# 2.1. Diastole lengths
check_phase$dias_half <- (check_phase$diaspat/2) # half length mean dias
check_phase$diaspat <- check_phase$diaspat # length mean dias

# overview mean length dias - in ms
summary(check_phase$diaspat) # length dias
sd(check_phase$diaspat)

# 2.2. Ranges for each trial (log_encode)
log_encode$start_dias <- (log_encode$Rtend_s + 0.05)*1000 # Rpeak until start diastole (after 50 ms window)
log_encode$end_dias <- (log_encode$Rtend_s + 0.05 + log_encode$diaspat)*1000 # Rpeak until end diastole (until next qwave onset)
log_encode$mid_dias <- ((log_encode$Rtend_s + 0.05) + (log_encode$diaspat/2))*1000 # Rpeak until mid diastole

# 2.1.Ranges for each subject (data_bins)
check_phase$start_dias <- tapply(log_encode$start_dias, log_encode$vp, unique) # all dias start at same time (after systole template + 50ms)

check_phase$end_dias_mean <- tapply(log_encode$end_dias, log_encode$vp, mean) # mean end dias per subject
check_phase$end_dias_sd <- tapply(log_encode$end_dias, log_encode$vp, sd) # sd end dias per subject

check_phase$mid_dias_mean <- tapply(log_encode$mid_dias, log_encode$vp, mean) # mean mid dias per subject
check_phase$mid_dias_med <- tapply(log_encode$mid_dias, log_encode$vp, median) # median mid dias per subject

check_phase$dias_sd <- tapply(log_encode$diaspat*1000, log_encode$vp, sd) # sd of dias lengths per subject

# overview mean start dias (over all participants) - in ms
summary(check_phase$start_dias) # mean dias starts from Rpeak (over all subjects)
sd(check_phase$start_dias) 

# overview mean end dias (over all participants) - in ms
summary(check_phase$end_dias_mean) # mean dias ends from Rpeak (over all subjects)
sd(check_phase$end_dias_mean)

#--------------------------------------------------------------------------
```



### 2.B. Plot phase ranges and lengths

* see also **Supplementary Figure S2**:
* 1. Cumulative frequency

```{r plot cumulative frequency}
#--------------------------------------------------------------------------
## 1. Cumulative frequency
# Prepare dataframe
melt_phase <- melt(check_phase, id= c("vp"), measure = c("syspat", "diaspat"))
colnames(melt_phase) <- c("vp", "phase", "length")

#--------------------------------------------------------------------------
# before plotting: load script `loadTHeme.R` and change legend parameter to enable legend

# pdf(file = paste(path_figures, "fig_cf_sysdias",".pdf",sep=""),width=4.5,height=4.5)
fig_cf_sysdias <- ggplot(data = melt_phase) +
  
  # histo sys dias
  geom_histogram(aes(length, fill = phase, col = phase), alpha = 0.8) +
  
  #  compute legend
  scale_colour_manual(name="Cardiac phase", values=c("syspat" = deforange, "diaspat"=defmedblue), 
labels=c(syspat="Systole", diaspat="Diastole")) +
  scale_fill_manual(name="Cardiac phase", values=c(syspat = deforange, diaspat=defmedblue), labels=c(syspat="Systole", diaspat="Diastole")) +
  
  # additional layer dias
  geom_histogram(data = check_phase, aes(diaspat), col = defmedblue, fill=defmedblue, alpha = 0.2)+ 
  labs(x = "Mean phase duration over participants (ms)", y = "Cumulative frequency") +
  
  mytheme +
  theme(legend.position = c(0.8, 0.9))

print(fig_cf_sysdias)
# dev.off()
```


* 2. Mean phase ranges for each participant (relative to R-peak)
```{r plot line ranges}
#--------------------------------------------------------------------------
## 2. Mean phase ranges

## Sort phases 
# according to mean end dias
check_phase$phase_rank <- as.numeric(rank((check_phase$syspat + check_phase$diaspat + check_phase$dias_sd), ties.method = "first")) 

# according to mean dias lengths
check_phase$length_rank <- as.numeric(rank(check_phase$diaspat, ties.method = "first"))

#--------------------------------------------------------------------------
#pdf(file = paste(path_figures, "fig_phase_lengths_new",".pdf",sep=""),width=4.5,height=4.5)

fig_phase_length <- ggplot(data=check_phase) + 
  
  ## systole - template range
  geom_linerange(aes(x = length_rank, ymin=mid_sys - sys_half,ymax=mid_sys + sys_half), col = deforange, size=1.5, linetype=1) + 

  ## diastole
  # range mean dias
  geom_linerange(aes(x=length_rank, ymin=mid_dias_mean - dias_half, ymax=mid_dias_mean + dias_half), col = defmedblue, size=1.5, linetype=1) + 
  
  geom_point(aes(x = length_rank, y=mid_dias_med)) + # mean midpoint
  
  # standard deviation
  geom_linerange(aes(x=length_rank, ymin=mid_dias_mean + dias_half, ymax=mid_dias_mean + dias_half + dias_sd), size=0.5, linetype=1) + 
  
  scale_y_continuous(breaks=seq(0, 1200, 200)) +
  labs(y = "Distance to previous Rpeak (ms)", x = "Participants") +
  coord_flip() + 
  mytheme 

print(fig_phase_length)
#dev.off()

#--------------------------------------------------------------------------
pdf(file = paste(path_figures, "dbl_phase", ".pdf", sep=""), width=10, height=4.5)
dbl_phase <- plot_grid(fig_cf_sysdias, fig_phase_length, ncol=2, align = "h", labels = c("a", "b"), label_size = 14)
dbl_phase
dev.off()
#--------------------------------------------------------------------------
```

